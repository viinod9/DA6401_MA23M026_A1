{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHwacXuTBDeQ",
        "outputId": "a14a2cfe-e8f0-4b4c-a9d5-bcf0f29fba10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.7)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.25.6)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.10.6)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.22.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.12.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYdAEZxGBOd9",
        "outputId": "162a05a7-f7fb-4f59-c374-97a755b518b0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mviinod9\u001b[0m (\u001b[33mviinod9-iitm\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "# Load and preprocess dataset\n",
        "def load_and_preprocess_data():\n",
        "    (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "    # Split into train and validation\n",
        "    val_size = 5000\n",
        "    x_val, y_val = x_train[:val_size], y_train[:val_size]\n",
        "    x_train, y_train = x_train[val_size:], y_train[val_size:]\n",
        "\n",
        "    # Normalize dataset\n",
        "    x_train, x_val, x_test = x_train / 255.0, x_val / 255.0, x_test / 255.0\n",
        "\n",
        "    # One-hot encoding\n",
        "    y_train = to_categorical(y_train, 10)\n",
        "    y_val = to_categorical(y_val, 10)\n",
        "    y_test = to_categorical(y_test, 10)\n",
        "\n",
        "    return x_train, y_train, x_val, y_val, x_test, y_test\n",
        "\n",
        "# Load data\n",
        "x_train, y_train, x_val, y_val, x_test, y_test = load_and_preprocess_data()\n",
        "\n",
        "# Define necessary functions\n",
        "def initialize_weights(num_hidden_layer, num_nodes_hidden_layers, weight, input_size, output_size):\n",
        "    weights = {}\n",
        "    prev_size = input_size\n",
        "    hidden_size = num_nodes_hidden_layers[0] if isinstance(num_nodes_hidden_layers, list) else num_nodes_hidden_layers\n",
        "\n",
        "    for i in range(num_hidden_layer):\n",
        "        if weight == 'random':\n",
        "            weights[f'W{i+1}'] = np.random.randn(prev_size, hidden_size) * 0.01\n",
        "        elif weight == 'xavier':\n",
        "            weights[f'W{i+1}'] = np.random.randn(prev_size, hidden_size) * np.sqrt(1 / prev_size)\n",
        "        weights[f'b{i+1}'] = np.zeros((1, hidden_size))\n",
        "        prev_size = hidden_size\n",
        "\n",
        "    if weight == 'random':\n",
        "        weights['W_out'] = np.random.randn(prev_size, output_size) * 0.01\n",
        "    elif weight == 'xavier':\n",
        "        weights['W_out'] = np.random.randn(prev_size, output_size) * np.sqrt(1 / prev_size)\n",
        "    weights['b_out'] = np.zeros((1, output_size))\n",
        "\n",
        "    return weights\n",
        "\n",
        "def activation_function(Z, activation):\n",
        "    if activation == 'sigmoid':\n",
        "        return 1 / (1 + np.exp(-Z))\n",
        "    elif activation == 'tanh':\n",
        "        return np.tanh(Z)\n",
        "    elif activation == 'relu':\n",
        "        return np.maximum(0, Z)\n",
        "    elif activation == 'softmax':\n",
        "        expZ = np.exp(Z - np.max(Z, axis=1, keepdims=True))\n",
        "        return expZ / np.sum(expZ, axis=1, keepdims=True)\n",
        "\n",
        "def derivative_activation(Z, activation):\n",
        "    if activation == 'sigmoid':\n",
        "        sig = activation_function(Z, 'sigmoid')\n",
        "        return sig * (1 - sig)\n",
        "    elif activation == 'tanh':\n",
        "        return 1 - np.tanh(Z)**2\n",
        "    elif activation == 'relu':\n",
        "        return (Z > 0).astype(float)\n",
        "\n",
        "def cross_entropy_loss(y_actual, y_pred):\n",
        "    return -np.mean(y_actual * np.log(y_pred + 1e-9))\n",
        "\n",
        "\n",
        "def mean_squared_error(y_actual, y_pred):\n",
        "    return np.mean((y_actual - y_pred) ** 2)\n",
        "\n",
        "\n",
        "def forward_propagation(X, weights, num_hidden_layer, activation):\n",
        "    A = X.reshape(X.shape[0], -1)\n",
        "    cache = {'A0': A}\n",
        "\n",
        "    for i in range(num_hidden_layer):\n",
        "        Z = np.dot(A, weights[f'W{i+1}']) + weights[f'b{i+1}']\n",
        "        A = activation_function(Z, activation)\n",
        "        cache[f'Z{i+1}'] = Z\n",
        "        cache[f'A{i+1}'] = A\n",
        "\n",
        "    Z_out = np.dot(A, weights['W_out']) + weights['b_out']\n",
        "    A_out = activation_function(Z_out, 'softmax')\n",
        "\n",
        "    cache['Z_out'] = Z_out\n",
        "    cache['A_out'] = A_out\n",
        "\n",
        "    return A_out, cache\n",
        "\n",
        "def back_propagation(X, y_actual, weights, cache, num_hidden_layer, activation):\n",
        "    gradients = {}\n",
        "    m = X.shape[0]\n",
        "\n",
        "    dZ_out = cache['A_out'] - y_actual\n",
        "    gradients['dW_out'] = np.dot(cache[f'A{num_hidden_layer}'].T, dZ_out) / m\n",
        "    gradients['db_out'] = np.sum(dZ_out, axis=0, keepdims=True) / m\n",
        "\n",
        "    dA = np.dot(dZ_out, weights['W_out'].T)\n",
        "\n",
        "    for i in range(num_hidden_layer, 0, -1):\n",
        "        dZ = dA * derivative_activation(cache[f'Z{i}'], activation)\n",
        "        gradients[f'dW{i}'] = np.dot(cache[f'A{i-1}'].T, dZ) / m\n",
        "        gradients[f'db{i}'] = np.sum(dZ, axis=0, keepdims=True) / m\n",
        "        dA = np.dot(dZ, weights[f'W{i}'].T)\n",
        "\n",
        "    return gradients\n",
        "\n",
        "def calculate_accuracy(X, y_actual, weights, num_hidden_layer, activation):\n",
        "    y_pred, _ = forward_propagation(X, weights, num_hidden_layer, activation)\n",
        "    return np.mean(np.argmax(y_pred, axis=1) == np.argmax(y_actual, axis=1))\n",
        "\n",
        "def stochastic_gradient_descent(lr, x_train, y_train, x_val, y_val, epochs, activation, num_hidden_layer, num_nodes_hidden_layers, weight, batch_size, input_size, output_size, loss_function='cross_entropy'):\n",
        "    wandb.init(project=\"stochastic\")\n",
        "    weights = initialize_weights(num_hidden_layer, num_nodes_hidden_layers, weight, input_size, output_size)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for i in range(0, x_train.shape[0], batch_size):\n",
        "            X_batch = x_train[i:i+batch_size]\n",
        "            y_batch = y_train[i:i+batch_size]\n",
        "\n",
        "            y_pred, cache = forward_propagation(X_batch, weights, num_hidden_layer, activation)\n",
        "            gradients = back_propagation(X_batch, y_batch, weights, cache, num_hidden_layer, activation)\n",
        "\n",
        "            for key in weights:\n",
        "                weights[key] -= lr * gradients[f'd{key}']\n",
        "\n",
        "        train_acc = calculate_accuracy(x_train, y_train, weights, num_hidden_layer, activation)\n",
        "        val_acc = calculate_accuracy(x_val, y_val, weights, num_hidden_layer, activation)\n",
        "\n",
        "        # Select loss function dynamically\n",
        "        if loss_function == 'cross_entropy':\n",
        "            train_loss = cross_entropy_loss(y_train, forward_propagation(x_train, weights, num_hidden_layer, activation)[0])\n",
        "            val_loss = cross_entropy_loss(y_val, forward_propagation(x_val, weights, num_hidden_layer, activation)[0])\n",
        "        elif loss_function == 'mse':\n",
        "            train_loss = mean_squared_error(y_train, forward_propagation(x_train, weights, num_hidden_layer, activation)[0])\n",
        "            val_loss = mean_squared_error(y_val, forward_propagation(x_val, weights, num_hidden_layer, activation)[0])\n",
        "\n",
        "        print(f\"Epoch {epoch+1}: Train Acc={train_acc:.4f}, Train Loss={train_loss:.4f}, Val Acc={val_acc:.4f}, Val Loss={val_loss:.4f}\")\n",
        "        wandb.log({\"train_acc\": train_acc, \"train_loss\": train_loss, \"val_acc\": val_acc, \"val_loss\": val_loss, \"epoch\": epoch + 1})\n",
        "\n",
        "    return weights\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Set parameters and train\n",
        "num_hidden_layer = 4\n",
        "num_nodes_hidden_layers = [128]\n",
        "weight = 'xavier'\n",
        "input_size = 28 * 28  # Flattened image size\n",
        "output_size = 10  # Number of classes\n",
        "lr = 0.01\n",
        "batch_size = 64\n",
        "epochs = 1\n",
        "activation = 'relu'\n",
        "\n",
        "trained_weights = stochastic_gradient_descent(lr, x_train, y_train, x_val, y_val, epochs, activation, num_hidden_layer, num_nodes_hidden_layers, weight, batch_size, input_size, output_size, loss_function='cross_entropy')\n",
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "id": "7P347_YoBPPc",
        "outputId": "9a6ba7b9-3fa7-4620-e728-03b4bf4e645b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250308_210303-8ammvny8</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/viinod9-iitm/stochastic/runs/8ammvny8' target=\"_blank\">bright-firefly-1</a></strong> to <a href='https://wandb.ai/viinod9-iitm/stochastic' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/viinod9-iitm/stochastic' target=\"_blank\">https://wandb.ai/viinod9-iitm/stochastic</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/viinod9-iitm/stochastic/runs/8ammvny8' target=\"_blank\">https://wandb.ai/viinod9-iitm/stochastic/runs/8ammvny8</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Acc=0.7354, Train Loss=0.0771, Val Acc=0.7406, Val Loss=0.0753\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>train_acc</td><td>▁</td></tr><tr><td>train_loss</td><td>▁</td></tr><tr><td>val_acc</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>1</td></tr><tr><td>train_acc</td><td>0.7354</td></tr><tr><td>train_loss</td><td>0.07707</td></tr><tr><td>val_acc</td><td>0.7406</td></tr><tr><td>val_loss</td><td>0.07525</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">bright-firefly-1</strong> at: <a href='https://wandb.ai/viinod9-iitm/stochastic/runs/8ammvny8' target=\"_blank\">https://wandb.ai/viinod9-iitm/stochastic/runs/8ammvny8</a><br> View project at: <a href='https://wandb.ai/viinod9-iitm/stochastic' target=\"_blank\">https://wandb.ai/viinod9-iitm/stochastic</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250308_210303-8ammvny8/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Modify momentum_gradient_descent to use either cross-entropy or MSE loss\n",
        "\n",
        "def momentum_gradient_descent(lr, x_train, y_train, x_val, y_val, epochs, activation, num_hidden_layer, num_nodes_hidden_layers, weight, batch_size, input_size, output_size, momentum=0.9, loss_function='cross_entropy'):\n",
        "    wandb.init(project=\"momentum\")\n",
        "    weights = initialize_weights(num_hidden_layer, num_nodes_hidden_layers, weight, input_size, output_size)\n",
        "    velocity = {key: np.zeros_like(value) for key, value in weights.items()}\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for i in range(0, x_train.shape[0], batch_size):\n",
        "            X_batch = x_train[i:i+batch_size]\n",
        "            y_batch = y_train[i:i+batch_size]\n",
        "            y_pred, cache = forward_propagation(X_batch, weights, num_hidden_layer, activation)\n",
        "            gradients = back_propagation(X_batch, y_batch, weights, cache, num_hidden_layer, activation)\n",
        "\n",
        "            for key in weights:\n",
        "                velocity[key] = momentum * velocity[key] - lr * gradients[f'd{key}']\n",
        "                weights[key] += velocity[key]\n",
        "\n",
        "        train_acc = calculate_accuracy(x_train, y_train, weights, num_hidden_layer, activation)\n",
        "        val_acc = calculate_accuracy(x_val, y_val, weights, num_hidden_layer, activation)\n",
        "\n",
        "        # Select loss function dynamically\n",
        "        if loss_function == 'cross_entropy':\n",
        "            train_loss = cross_entropy_loss(y_train, forward_propagation(x_train, weights, num_hidden_layer, activation)[0])\n",
        "            val_loss = cross_entropy_loss(y_val, forward_propagation(x_val, weights, num_hidden_layer, activation)[0])\n",
        "        elif loss_function == 'mse':\n",
        "            train_loss = mean_squared_error(y_train, forward_propagation(x_train, weights, num_hidden_layer, activation)[0])\n",
        "            val_loss = mean_squared_error(y_val, forward_propagation(x_val, weights, num_hidden_layer, activation)[0])\n",
        "\n",
        "        print(f\"Epoch {epoch+1}: Train Acc={train_acc:.4f}, Train Loss={train_loss:.4f}, Val Acc={val_acc:.4f}, Val Loss={val_loss:.4f}\")\n",
        "        wandb.log({\"train_acc\": train_acc, \"train_loss\": train_loss, \"val_acc\": val_acc, \"val_loss\": val_loss, \"epoch\": epoch + 1})\n",
        "\n",
        "    return weights\n",
        "\n",
        "# Example usage\n",
        "\n",
        "\n",
        "# Set parameters and train\n",
        "num_hidden_layer = 3\n",
        "num_nodes_hidden_layers = [128]\n",
        "weight = 'xavier'\n",
        "input_size = 28 * 28  # Flattened image size\n",
        "output_size = 10  # Number of classes\n",
        "lr = 0.01\n",
        "batch_size = 64\n",
        "epochs = 1\n",
        "activation = 'relu'\n",
        "trained_weights1 = momentum_gradient_descent(lr, x_train, y_train, x_val, y_val, epochs, activation, num_hidden_layer, num_nodes_hidden_layers, weight, batch_size, input_size, output_size, momentum=0.9, loss_function='cross_entropy')\n",
        "wandb.finish()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "id": "Lr8iB-N6C2zG",
        "outputId": "aea589ac-9597-48c8-c9e4-08a883353677"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250308_210310-wt97c775</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/viinod9-iitm/momentum/runs/wt97c775' target=\"_blank\">clear-hill-1</a></strong> to <a href='https://wandb.ai/viinod9-iitm/momentum' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/viinod9-iitm/momentum' target=\"_blank\">https://wandb.ai/viinod9-iitm/momentum</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/viinod9-iitm/momentum/runs/wt97c775' target=\"_blank\">https://wandb.ai/viinod9-iitm/momentum/runs/wt97c775</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Acc=0.8303, Train Loss=0.0459, Val Acc=0.8340, Val Loss=0.0456\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>train_acc</td><td>▁</td></tr><tr><td>train_loss</td><td>▁</td></tr><tr><td>val_acc</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>1</td></tr><tr><td>train_acc</td><td>0.83033</td></tr><tr><td>train_loss</td><td>0.0459</td></tr><tr><td>val_acc</td><td>0.834</td></tr><tr><td>val_loss</td><td>0.04555</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">clear-hill-1</strong> at: <a href='https://wandb.ai/viinod9-iitm/momentum/runs/wt97c775' target=\"_blank\">https://wandb.ai/viinod9-iitm/momentum/runs/wt97c775</a><br> View project at: <a href='https://wandb.ai/viinod9-iitm/momentum' target=\"_blank\">https://wandb.ai/viinod9-iitm/momentum</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250308_210310-wt97c775/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def nesterov_gradient_descent(lr, x_train, y_train, x_val, y_val, epochs, activation, num_hidden_layer, num_nodes_hidden_layers, weight, batch_size, input_size, output_size, momentum=0.9, loss_function='cross_entropy'):\n",
        "    wandb.init(project=\"nesterov\")\n",
        "    weights = initialize_weights(num_hidden_layer, num_nodes_hidden_layers, weight, input_size, output_size)\n",
        "    velocity = {key: np.zeros_like(value) for key, value in weights.items()}\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for i in range(0, x_train.shape[0], batch_size):\n",
        "            temp_weights = {key: weights[key] + momentum * velocity[key] for key in weights}\n",
        "            X_batch = x_train[i:i+batch_size]\n",
        "            y_batch = y_train[i:i+batch_size]\n",
        "            y_pred, cache = forward_propagation(X_batch, temp_weights, num_hidden_layer, activation)\n",
        "            gradients = back_propagation(X_batch, y_batch, temp_weights, cache, num_hidden_layer, activation)\n",
        "\n",
        "            for key in weights:\n",
        "                velocity[key] = momentum * velocity[key] - lr * gradients[f'd{key}']\n",
        "                weights[key] += velocity[key]\n",
        "\n",
        "        train_acc = calculate_accuracy(x_train, y_train, weights, num_hidden_layer, activation)\n",
        "        val_acc = calculate_accuracy(x_val, y_val, weights, num_hidden_layer, activation)\n",
        "\n",
        "        # Select loss function dynamically\n",
        "        if loss_function == 'cross_entropy':\n",
        "            train_loss = cross_entropy_loss(y_train, forward_propagation(x_train, weights, num_hidden_layer, activation)[0])\n",
        "            val_loss = cross_entropy_loss(y_val, forward_propagation(x_val, weights, num_hidden_layer, activation)[0])\n",
        "        elif loss_function == 'mse':\n",
        "            train_loss = mean_squared_error(y_train, forward_propagation(x_train, weights, num_hidden_layer, activation)[0])\n",
        "            val_loss = mean_squared_error(y_val, forward_propagation(x_val, weights, num_hidden_layer, activation)[0])\n",
        "\n",
        "        print(f\"Epoch {epoch+1}: Train Acc={train_acc:.4f}, Train Loss={train_loss:.4f}, Val Acc={val_acc:.4f}, Val Loss={val_loss:.4f}\")\n",
        "        wandb.log({\"train_acc\": train_acc, \"train_loss\": train_loss, \"val_acc\": val_acc, \"val_loss\": val_loss, \"epoch\": epoch + 1})\n",
        "\n",
        "    return weights\n",
        "\n",
        "# Example usage\n",
        "\n",
        "\n",
        "# Set parameters and train\n",
        "num_hidden_layer = 5\n",
        "num_nodes_hidden_layers = [128]\n",
        "weight = 'xavier'\n",
        "input_size = 28 * 28  # Flattened image size\n",
        "output_size = 10  # Number of classes\n",
        "lr = 0.01\n",
        "batch_size = 64\n",
        "epochs = 1\n",
        "activation = 'relu'\n",
        "\n",
        "trained_weights2 = nesterov_gradient_descent(lr, x_train, y_train, x_val, y_val, epochs, activation, num_hidden_layer, num_nodes_hidden_layers, weight, batch_size, input_size, output_size, momentum=0.9, loss_function='cross_entropy')\n",
        "wandb.finish()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "id": "lA5AYkawEFe4",
        "outputId": "99d6b093-fbfd-4b85-b3f5-6ba446c7e8fc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250308_210317-e0xgol39</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/viinod9-iitm/nesterov/runs/e0xgol39' target=\"_blank\">unique-water-1</a></strong> to <a href='https://wandb.ai/viinod9-iitm/nesterov' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/viinod9-iitm/nesterov' target=\"_blank\">https://wandb.ai/viinod9-iitm/nesterov</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/viinod9-iitm/nesterov/runs/e0xgol39' target=\"_blank\">https://wandb.ai/viinod9-iitm/nesterov/runs/e0xgol39</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Acc=0.8514, Train Loss=0.0411, Val Acc=0.8528, Val Loss=0.0415\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>train_acc</td><td>▁</td></tr><tr><td>train_loss</td><td>▁</td></tr><tr><td>val_acc</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>1</td></tr><tr><td>train_acc</td><td>0.85144</td></tr><tr><td>train_loss</td><td>0.04111</td></tr><tr><td>val_acc</td><td>0.8528</td></tr><tr><td>val_loss</td><td>0.04146</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">unique-water-1</strong> at: <a href='https://wandb.ai/viinod9-iitm/nesterov/runs/e0xgol39' target=\"_blank\">https://wandb.ai/viinod9-iitm/nesterov/runs/e0xgol39</a><br> View project at: <a href='https://wandb.ai/viinod9-iitm/nesterov' target=\"_blank\">https://wandb.ai/viinod9-iitm/nesterov</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250308_210317-e0xgol39/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def rmsprop_optimizer(lr, x_train, y_train, x_val, y_val, epochs, activation, num_hidden_layer, num_nodes_hidden_layers, weight, batch_size, input_size, output_size, beta=0.9, epsilon=1e-8, loss_function='cross_entropy'):\n",
        "    wandb.init(project=\"rmsprop\")\n",
        "    weights = initialize_weights(num_hidden_layer, num_nodes_hidden_layers, weight, input_size, output_size)\n",
        "    cache = {key: np.zeros_like(value) for key, value in weights.items()}\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for i in range(0, x_train.shape[0], batch_size):\n",
        "            X_batch = x_train[i:i+batch_size]\n",
        "            y_batch = y_train[i:i+batch_size]\n",
        "            y_pred, cache_forward = forward_propagation(X_batch, weights, num_hidden_layer, activation)\n",
        "            gradients = back_propagation(X_batch, y_batch, weights, cache_forward, num_hidden_layer, activation)\n",
        "\n",
        "            for key in weights:\n",
        "                cache[key] = beta * cache[key] + (1 - beta) * gradients[f'd{key}']**2\n",
        "                weights[key] -= lr * gradients[f'd{key}'] / (np.sqrt(cache[key]) + epsilon)\n",
        "\n",
        "        train_acc = calculate_accuracy(x_train, y_train, weights, num_hidden_layer, activation)\n",
        "        val_acc = calculate_accuracy(x_val, y_val, weights, num_hidden_layer, activation)\n",
        "\n",
        "        # Select loss function dynamically\n",
        "        if loss_function == 'cross_entropy':\n",
        "            train_loss = cross_entropy_loss(y_train, forward_propagation(x_train, weights, num_hidden_layer, activation)[0])\n",
        "            val_loss = cross_entropy_loss(y_val, forward_propagation(x_val, weights, num_hidden_layer, activation)[0])\n",
        "        elif loss_function == 'mse':\n",
        "            train_loss = mean_squared_error(y_train, forward_propagation(x_train, weights, num_hidden_layer, activation)[0])\n",
        "            val_loss = mean_squared_error(y_val, forward_propagation(x_val, weights, num_hidden_layer, activation)[0])\n",
        "\n",
        "        print(f\"Epoch {epoch+1}: Train Acc={train_acc:.4f}, Train Loss={train_loss:.4f}, Val Acc={val_acc:.4f}, Val Loss={val_loss:.4f}\")\n",
        "        wandb.log({\"train_acc\": train_acc, \"train_loss\": train_loss, \"val_acc\": val_acc, \"val_loss\": val_loss, \"epoch\": epoch + 1})\n",
        "\n",
        "    return weights\n",
        "\n",
        "# Example usage\n",
        "\n",
        "# Set parameters and train\n",
        "num_hidden_layer = 4\n",
        "num_nodes_hidden_layers = [128]\n",
        "weight = 'xavier'\n",
        "input_size = 28 * 28  # Flattened image size\n",
        "output_size = 10  # Number of classes\n",
        "lr = 0.01\n",
        "batch_size = 64\n",
        "epochs = 1\n",
        "activation = 'sigmoid'\n",
        "\n",
        "\n",
        "trained_weights3 = rmsprop_optimizer(lr, x_train, y_train, x_val, y_val, epochs, activation, num_hidden_layer, num_nodes_hidden_layers, weight, batch_size, input_size, output_size, beta=0.9, epsilon=1e-8, loss_function='cross_entropy')\n",
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "id": "Gao99M_1Elja",
        "outputId": "99e62fc2-2730-4dc0-cf08-7eea3ac060bf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250308_210325-pb7ovzpa</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/viinod9-iitm/rmsprop/runs/pb7ovzpa' target=\"_blank\">skilled-capybara-1</a></strong> to <a href='https://wandb.ai/viinod9-iitm/rmsprop' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/viinod9-iitm/rmsprop' target=\"_blank\">https://wandb.ai/viinod9-iitm/rmsprop</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/viinod9-iitm/rmsprop/runs/pb7ovzpa' target=\"_blank\">https://wandb.ai/viinod9-iitm/rmsprop/runs/pb7ovzpa</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Acc=0.7958, Train Loss=0.0572, Val Acc=0.7950, Val Loss=0.0576\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>train_acc</td><td>▁</td></tr><tr><td>train_loss</td><td>▁</td></tr><tr><td>val_acc</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>1</td></tr><tr><td>train_acc</td><td>0.79584</td></tr><tr><td>train_loss</td><td>0.05722</td></tr><tr><td>val_acc</td><td>0.795</td></tr><tr><td>val_loss</td><td>0.05764</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">skilled-capybara-1</strong> at: <a href='https://wandb.ai/viinod9-iitm/rmsprop/runs/pb7ovzpa' target=\"_blank\">https://wandb.ai/viinod9-iitm/rmsprop/runs/pb7ovzpa</a><br> View project at: <a href='https://wandb.ai/viinod9-iitm/rmsprop' target=\"_blank\">https://wandb.ai/viinod9-iitm/rmsprop</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250308_210325-pb7ovzpa/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def adam_optimizer(lr, x_train, y_train, x_val, y_val, epochs, activation, num_hidden_layer, num_nodes_hidden_layers, weight, batch_size, input_size, output_size, beta1=0.9, beta2=0.999, epsilon=1e-8, loss_function='cross_entropy'):\n",
        "    wandb.init(project=\"adam\")\n",
        "    weights = initialize_weights(num_hidden_layer, num_nodes_hidden_layers, weight, input_size, output_size)\n",
        "    m = {key: np.zeros_like(value) for key, value in weights.items()}\n",
        "    v = {key: np.zeros_like(value) for key, value in weights.items()}\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for i in range(0, x_train.shape[0], batch_size):\n",
        "            X_batch = x_train[i:i+batch_size]\n",
        "            y_batch = y_train[i:i+batch_size]\n",
        "            y_pred, cache_forward = forward_propagation(X_batch, weights, num_hidden_layer, activation)\n",
        "            gradients = back_propagation(X_batch, y_batch, weights, cache_forward, num_hidden_layer, activation)\n",
        "\n",
        "            for key in weights:\n",
        "                m[key] = beta1 * m[key] + (1 - beta1) * gradients[f'd{key}']\n",
        "                v[key] = beta2 * v[key] + (1 - beta2) * (gradients[f'd{key}'] ** 2)\n",
        "                m_hat = m[key] / (1 - beta1 ** (epoch + 1))\n",
        "                v_hat = v[key] / (1 - beta2 ** (epoch + 1))\n",
        "                weights[key] -= lr * m_hat / (np.sqrt(v_hat) + epsilon)\n",
        "\n",
        "        train_acc = calculate_accuracy(x_train, y_train, weights, num_hidden_layer, activation)\n",
        "        val_acc = calculate_accuracy(x_val, y_val, weights, num_hidden_layer, activation)\n",
        "\n",
        "        # Select loss function dynamically\n",
        "        if loss_function == 'cross_entropy':\n",
        "            train_loss = cross_entropy_loss(y_train, forward_propagation(x_train, weights, num_hidden_layer, activation)[0])\n",
        "            val_loss = cross_entropy_loss(y_val, forward_propagation(x_val, weights, num_hidden_layer, activation)[0])\n",
        "        elif loss_function == 'mse':\n",
        "            train_loss = mean_squared_error(y_train, forward_propagation(x_train, weights, num_hidden_layer, activation)[0])\n",
        "            val_loss = mean_squared_error(y_val, forward_propagation(x_val, weights, num_hidden_layer, activation)[0])\n",
        "\n",
        "        print(f\"Epoch {epoch+1}: Train Acc={train_acc:.4f}, Train Loss={train_loss:.4f}, Val Acc={val_acc:.4f}, Val Loss={val_loss:.4f}\")\n",
        "        wandb.log({\"train_acc\": train_acc, \"train_loss\": train_loss, \"val_acc\": val_acc, \"val_loss\": val_loss, \"epoch\": epoch + 1})\n",
        "\n",
        "    return weights\n",
        "\n",
        "# Example usage\n",
        "\n",
        "# Set parameters and train\n",
        "num_hidden_layer = 4\n",
        "num_nodes_hidden_layers = [128]\n",
        "weight = 'xavier'\n",
        "input_size = 28 * 28  # Flattened image size\n",
        "output_size = 10  # Number of classes\n",
        "lr = 0.01\n",
        "batch_size = 64\n",
        "epochs = 1\n",
        "activation = 'sigmoid'\n",
        "\n",
        "\n",
        "trained_weights4 = adam_optimizer(lr, x_train, y_train, x_val, y_val, epochs, activation, num_hidden_layer, num_nodes_hidden_layers, weight, batch_size, input_size, output_size, beta1=0.9, beta2=0.999, epsilon=1e-8, loss_function='cross_entropy')\n",
        "wandb.finish()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "id": "HX46WMxiFECN",
        "outputId": "5aee9ce8-941b-4ea8-adbf-10b1f85bf328"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250308_210334-6ygal2q4</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/viinod9-iitm/adam/runs/6ygal2q4' target=\"_blank\">clear-frost-1</a></strong> to <a href='https://wandb.ai/viinod9-iitm/adam' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/viinod9-iitm/adam' target=\"_blank\">https://wandb.ai/viinod9-iitm/adam</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/viinod9-iitm/adam/runs/6ygal2q4' target=\"_blank\">https://wandb.ai/viinod9-iitm/adam/runs/6ygal2q4</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Acc=0.8282, Train Loss=0.0488, Val Acc=0.8378, Val Loss=0.0480\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>train_acc</td><td>▁</td></tr><tr><td>train_loss</td><td>▁</td></tr><tr><td>val_acc</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>1</td></tr><tr><td>train_acc</td><td>0.82822</td></tr><tr><td>train_loss</td><td>0.04879</td></tr><tr><td>val_acc</td><td>0.8378</td></tr><tr><td>val_loss</td><td>0.04803</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">clear-frost-1</strong> at: <a href='https://wandb.ai/viinod9-iitm/adam/runs/6ygal2q4' target=\"_blank\">https://wandb.ai/viinod9-iitm/adam/runs/6ygal2q4</a><br> View project at: <a href='https://wandb.ai/viinod9-iitm/adam' target=\"_blank\">https://wandb.ai/viinod9-iitm/adam</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250308_210334-6ygal2q4/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def nadam_optimizer(lr, x_train, y_train, x_val, y_val, epochs, activation, num_hidden_layer, num_nodes_hidden_layers, weight, batch_size, input_size, output_size, beta1=0.9, beta2=0.999, epsilon=1e-8, loss_function='cross_entropy'):\n",
        "    wandb.init(project=\"nadam\")\n",
        "    weights = initialize_weights(num_hidden_layer, num_nodes_hidden_layers, weight, input_size, output_size)\n",
        "    m = {key: np.zeros_like(value) for key, value in weights.items()}\n",
        "    v = {key: np.zeros_like(value) for key, value in weights.items()}\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for i in range(0, x_train.shape[0], batch_size):\n",
        "            X_batch = x_train[i:i+batch_size]\n",
        "            y_batch = y_train[i:i+batch_size]\n",
        "            y_pred, cache_forward = forward_propagation(X_batch, weights, num_hidden_layer, activation)\n",
        "            gradients = back_propagation(X_batch, y_batch, weights, cache_forward, num_hidden_layer, activation)\n",
        "\n",
        "            for key in weights:\n",
        "                m[key] = beta1 * m[key] + (1 - beta1) * gradients[f'd{key}']\n",
        "                v[key] = beta2 * v[key] + (1 - beta2) * (gradients[f'd{key}'] ** 2)\n",
        "                m_hat = m[key] / (1 - beta1 ** (epoch + 1))\n",
        "                v_hat = v[key] / (1 - beta2 ** (epoch + 1))\n",
        "                nadam_update = beta1 * m_hat + (1 - beta1) * gradients[f'd{key}']\n",
        "                weights[key] -= lr * nadam_update / (np.sqrt(v_hat) + epsilon)\n",
        "\n",
        "        train_acc = calculate_accuracy(x_train, y_train, weights, num_hidden_layer, activation)\n",
        "        val_acc = calculate_accuracy(x_val, y_val, weights, num_hidden_layer, activation)\n",
        "\n",
        "        # Select loss function dynamically\n",
        "        if loss_function == 'cross_entropy':\n",
        "            train_loss = cross_entropy_loss(y_train, forward_propagation(x_train, weights, num_hidden_layer, activation)[0])\n",
        "            val_loss = cross_entropy_loss(y_val, forward_propagation(x_val, weights, num_hidden_layer, activation)[0])\n",
        "        elif loss_function == 'mse':\n",
        "            train_loss = mean_squared_error(y_train, forward_propagation(x_train, weights, num_hidden_layer, activation)[0])\n",
        "            val_loss = mean_squared_error(y_val, forward_propagation(x_val, weights, num_hidden_layer, activation)[0])\n",
        "\n",
        "        print(f\"Epoch {epoch+1}: Train Acc={train_acc:.4f}, Train Loss={train_loss:.4f}, Val Acc={val_acc:.4f}, Val Loss={val_loss:.4f}\")\n",
        "        wandb.log({\"train_acc\": train_acc, \"train_loss\": train_loss, \"val_acc\": val_acc, \"val_loss\": val_loss, \"epoch\": epoch + 1})\n",
        "\n",
        "    return weights\n",
        "\n",
        "# Example usage\n",
        "\n",
        "# Set parameters and train\n",
        "num_hidden_layer = 4\n",
        "num_nodes_hidden_layers = [128]\n",
        "weight = 'xavier'\n",
        "input_size = 28 * 28  # Flattened image size\n",
        "output_size = 10  # Number of classes\n",
        "lr = 0.01\n",
        "batch_size = 64\n",
        "epochs = 4\n",
        "activation = 'sigmoid'\n",
        "\n",
        "trained_weights5 = nadam_optimizer(lr, x_train, y_train, x_val, y_val, epochs, activation, num_hidden_layer, num_nodes_hidden_layers, weight, batch_size, input_size, output_size, beta1=0.9, beta2=0.999, epsilon=1e-8, loss_function='cross_entropy')\n",
        "wandb.finish()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "id": "UmIkLNzSFrm2",
        "outputId": "35838ee5-ef13-4aa5-9b8e-52061b8619d6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250308_210343-thkg62vr</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/viinod9-iitm/nadam/runs/thkg62vr' target=\"_blank\">firm-lake-1</a></strong> to <a href='https://wandb.ai/viinod9-iitm/nadam' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/viinod9-iitm/nadam' target=\"_blank\">https://wandb.ai/viinod9-iitm/nadam</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/viinod9-iitm/nadam/runs/thkg62vr' target=\"_blank\">https://wandb.ai/viinod9-iitm/nadam/runs/thkg62vr</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Acc=0.8304, Train Loss=0.0474, Val Acc=0.8284, Val Loss=0.0493\n",
            "Epoch 2: Train Acc=0.8655, Train Loss=0.0379, Val Acc=0.8570, Val Loss=0.0397\n",
            "Epoch 3: Train Acc=0.8792, Train Loss=0.0339, Val Acc=0.8654, Val Loss=0.0368\n",
            "Epoch 4: Train Acc=0.8848, Train Loss=0.0317, Val Acc=0.8712, Val Loss=0.0352\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▃▆█</td></tr><tr><td>train_acc</td><td>▁▆▇█</td></tr><tr><td>train_loss</td><td>█▄▂▁</td></tr><tr><td>val_acc</td><td>▁▆▇█</td></tr><tr><td>val_loss</td><td>█▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>4</td></tr><tr><td>train_acc</td><td>0.88482</td></tr><tr><td>train_loss</td><td>0.03168</td></tr><tr><td>val_acc</td><td>0.8712</td></tr><tr><td>val_loss</td><td>0.0352</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">firm-lake-1</strong> at: <a href='https://wandb.ai/viinod9-iitm/nadam/runs/thkg62vr' target=\"_blank\">https://wandb.ai/viinod9-iitm/nadam/runs/thkg62vr</a><br> View project at: <a href='https://wandb.ai/viinod9-iitm/nadam' target=\"_blank\">https://wandb.ai/viinod9-iitm/nadam</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250308_210343-thkg62vr/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question - 4 , 5 , 6"
      ],
      "metadata": {
        "id": "PtOIIfJFxWDO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import wandb\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "\n",
        "def main():\n",
        "    sweep_config = {\n",
        "        'method': 'bayes',\n",
        "        'metric': {'name': 'accuracy', 'goal': 'maximize'},\n",
        "        'parameters': {\n",
        "            'epochs': {'values': [5, 10]},\n",
        "            'num_layers': {'values': [3, 4, 5]},\n",
        "            'hidden_size': {'values': [32, 64, 128]},\n",
        "            'weight_decay': {'values': [0, 0.0005, 0.5]},\n",
        "            'learning_rate': {'values': [1e-3, 1e-4]},\n",
        "            'optimizer': {'values': ['stochastic', 'momentum', 'nag', 'rmsprop', 'adam', 'nadam']},\n",
        "            'batch_size': {'values': [16, 32, 64]},\n",
        "            'weight_init': {'values': ['random', 'xavier']},\n",
        "            'activation': {'values': ['sigmoid', 'tanh', 'relu']},\n",
        "        }\n",
        "    }\n",
        "    sweep_id = wandb.sweep(sweep_config, project=\"fashion-mnist-nn\")\n",
        "    wandb.agent(sweep_id, function=train, count=3)\n",
        "\n",
        "def train():\n",
        "    wandb.init(project=\"Vinod_A1\")\n",
        "    # wandb.init()\n",
        "    config = wandb.config\n",
        "    run_name = f\"Opt-{config.optimizer}_Layers-{config.num_layers}_HS-{config.hidden_size}_LR-{config.learning_rate}_Batch-{config.batch_size}_Act-{config.activation}\"\n",
        "    wandb.run.name = run_name\n",
        "\n",
        "    # x_train, y_train, x_val, y_val, _, _ = load_and_preprocess_data()\n",
        "\n",
        "    optimizer = config.optimizer\n",
        "\n",
        "    if optimizer == 'stochastic':\n",
        "        trained_weights = stochastic_gradient_descent(config.learning_rate, x_train, y_train, x_val, y_val, config.epochs, config.activation, config.num_layers, config.hidden_size, config.weight_init, config.batch_size, 28*28, 10, loss_function='cross_entropy')\n",
        "        # trained_weights = stochastic_gradient_descent(lr, x_train, y_train, x_val, y_val, epochs, activation, num_hidden_layer, num_nodes_hidden_layers, weight, batch_size, input_size, output_size)\n",
        "    elif optimizer == 'momentum':\n",
        "        trained_weights = momentum_gradient_descent(config.learning_rate, x_train, y_train, x_val, y_val, config.epochs, config.activation, config.num_layers, config.hidden_size, config.weight_init, config.batch_size, 28*28, 10, loss_function='cross_entropy')\n",
        "    elif optimizer == 'nag':\n",
        "        trained_weights = nesterov_gradient_descent(config.learning_rate, x_train, y_train, x_val, y_val, config.epochs, config.activation, config.num_layers, config.hidden_size, config.weight_init, config.batch_size, 28*28, 10, loss_function='cross_entropy')\n",
        "    elif optimizer == 'rmsprop':\n",
        "        trained_weights = rmsprop_optimizer(config.learning_rate, x_train, y_train, x_val, y_val, config.epochs, config.activation, config.num_layers, config.hidden_size, config.weight_init, config.batch_size, 28*28, 10, loss_function='cross_entropy')\n",
        "    elif optimizer == 'adam':\n",
        "        trained_weights = adam_optimizer(config.learning_rate, x_train, y_train, x_val, y_val, config.epochs, config.activation, config.num_layers, config.hidden_size, config.weight_init, config.batch_size, 28*28, 10, loss_function='cross_entropy')\n",
        "    elif optimizer == 'nadam':\n",
        "        trained_weights = nadam_optimizer(config.learning_rate, x_train, y_train, x_val, y_val, config.epochs, config.activation, config.num_layers, config.hidden_size, config.weight_init, config.batch_size, 28*28, 10, loss_function='cross_entropy')\n",
        "\n",
        "    #wandb.log({\"train_acc\": train_acc, \"train_loss\": train_loss, \"val_acc\": val_acc, \"val_loss\": val_loss})\n",
        "\n",
        "    wandb.finish()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Q_tbY4i6GEZQ",
        "outputId": "a920e017-ac7f-4f9f-cac0-0064da102d12"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: nc8rvczp\n",
            "Sweep URL: https://wandb.ai/viinod9-iitm/fashion-mnist-nn/sweeps/nc8rvczp\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: rsrln0bc with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_init: xavier\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Ignoring project 'Vinod_A1' when running a sweep."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250308_210417-rsrln0bc</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/viinod9-iitm/fashion-mnist-nn/runs/rsrln0bc' target=\"_blank\">peachy-sweep-1</a></strong> to <a href='https://wandb.ai/viinod9-iitm/fashion-mnist-nn' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/viinod9-iitm/fashion-mnist-nn/sweeps/nc8rvczp' target=\"_blank\">https://wandb.ai/viinod9-iitm/fashion-mnist-nn/sweeps/nc8rvczp</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/viinod9-iitm/fashion-mnist-nn' target=\"_blank\">https://wandb.ai/viinod9-iitm/fashion-mnist-nn</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/viinod9-iitm/fashion-mnist-nn/sweeps/nc8rvczp' target=\"_blank\">https://wandb.ai/viinod9-iitm/fashion-mnist-nn/sweeps/nc8rvczp</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/viinod9-iitm/fashion-mnist-nn/runs/rsrln0bc' target=\"_blank\">https://wandb.ai/viinod9-iitm/fashion-mnist-nn/runs/rsrln0bc</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Ignoring project 'rmsprop' when running a sweep."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Acc=0.8484, Train Loss=0.0424, Val Acc=0.8474, Val Loss=0.0420\n",
            "Epoch 2: Train Acc=0.8622, Train Loss=0.0383, Val Acc=0.8606, Val Loss=0.0387\n",
            "Epoch 3: Train Acc=0.8698, Train Loss=0.0362, Val Acc=0.8652, Val Loss=0.0372\n",
            "Epoch 4: Train Acc=0.8752, Train Loss=0.0347, Val Acc=0.8676, Val Loss=0.0362\n",
            "Epoch 5: Train Acc=0.8792, Train Loss=0.0335, Val Acc=0.8702, Val Loss=0.0355\n",
            "Epoch 6: Train Acc=0.8824, Train Loss=0.0325, Val Acc=0.8730, Val Loss=0.0350\n",
            "Epoch 7: Train Acc=0.8860, Train Loss=0.0316, Val Acc=0.8762, Val Loss=0.0344\n",
            "Epoch 8: Train Acc=0.8890, Train Loss=0.0308, Val Acc=0.8782, Val Loss=0.0340\n",
            "Epoch 9: Train Acc=0.8916, Train Loss=0.0300, Val Acc=0.8814, Val Loss=0.0336\n",
            "Epoch 10: Train Acc=0.8940, Train Loss=0.0293, Val Acc=0.8816, Val Loss=0.0332\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_acc</td><td>▁▃▄▅▆▆▇▇██</td></tr><tr><td>train_loss</td><td>█▆▅▄▃▃▂▂▁▁</td></tr><tr><td>val_acc</td><td>▁▄▅▅▆▆▇▇██</td></tr><tr><td>val_loss</td><td>█▅▄▃▃▂▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>train_acc</td><td>0.89398</td></tr><tr><td>train_loss</td><td>0.02928</td></tr><tr><td>val_acc</td><td>0.8816</td></tr><tr><td>val_loss</td><td>0.03322</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">Opt-rmsprop_Layers-3_HS-128_LR-0.0001_Batch-16_Act-tanh</strong> at: <a href='https://wandb.ai/viinod9-iitm/fashion-mnist-nn/runs/rsrln0bc' target=\"_blank\">https://wandb.ai/viinod9-iitm/fashion-mnist-nn/runs/rsrln0bc</a><br> View project at: <a href='https://wandb.ai/viinod9-iitm/fashion-mnist-nn' target=\"_blank\">https://wandb.ai/viinod9-iitm/fashion-mnist-nn</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250308_210417-rsrln0bc/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: cgsgal8g with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: momentum\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0005\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_init: xavier\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Ignoring project 'Vinod_A1' when running a sweep."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250308_210600-cgsgal8g</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/viinod9-iitm/fashion-mnist-nn/runs/cgsgal8g' target=\"_blank\">crisp-sweep-2</a></strong> to <a href='https://wandb.ai/viinod9-iitm/fashion-mnist-nn' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/viinod9-iitm/fashion-mnist-nn/sweeps/nc8rvczp' target=\"_blank\">https://wandb.ai/viinod9-iitm/fashion-mnist-nn/sweeps/nc8rvczp</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/viinod9-iitm/fashion-mnist-nn' target=\"_blank\">https://wandb.ai/viinod9-iitm/fashion-mnist-nn</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/viinod9-iitm/fashion-mnist-nn/sweeps/nc8rvczp' target=\"_blank\">https://wandb.ai/viinod9-iitm/fashion-mnist-nn/sweeps/nc8rvczp</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/viinod9-iitm/fashion-mnist-nn/runs/cgsgal8g' target=\"_blank\">https://wandb.ai/viinod9-iitm/fashion-mnist-nn/runs/cgsgal8g</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Ignoring project 'momentum' when running a sweep."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Acc=0.8057, Train Loss=0.0555, Val Acc=0.8096, Val Loss=0.0548\n",
            "Epoch 2: Train Acc=0.8335, Train Loss=0.0473, Val Acc=0.8338, Val Loss=0.0468\n",
            "Epoch 3: Train Acc=0.8454, Train Loss=0.0438, Val Acc=0.8438, Val Loss=0.0437\n",
            "Epoch 4: Train Acc=0.8542, Train Loss=0.0414, Val Acc=0.8508, Val Loss=0.0417\n",
            "Epoch 5: Train Acc=0.8619, Train Loss=0.0390, Val Acc=0.8626, Val Loss=0.0395\n",
            "Epoch 6: Train Acc=0.8691, Train Loss=0.0370, Val Acc=0.8674, Val Loss=0.0379\n",
            "Epoch 7: Train Acc=0.8734, Train Loss=0.0357, Val Acc=0.8698, Val Loss=0.0369\n",
            "Epoch 8: Train Acc=0.8768, Train Loss=0.0346, Val Acc=0.8722, Val Loss=0.0360\n",
            "Epoch 9: Train Acc=0.8795, Train Loss=0.0336, Val Acc=0.8754, Val Loss=0.0353\n",
            "Epoch 10: Train Acc=0.8818, Train Loss=0.0328, Val Acc=0.8774, Val Loss=0.0349\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_acc</td><td>▁▄▅▅▆▇▇███</td></tr><tr><td>train_loss</td><td>█▅▄▄▃▂▂▂▁▁</td></tr><tr><td>val_acc</td><td>▁▃▅▅▆▇▇▇██</td></tr><tr><td>val_loss</td><td>█▅▄▃▃▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>train_acc</td><td>0.88176</td></tr><tr><td>train_loss</td><td>0.03284</td></tr><tr><td>val_acc</td><td>0.8774</td></tr><tr><td>val_loss</td><td>0.03486</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">Opt-momentum_Layers-3_HS-128_LR-0.001_Batch-32_Act-relu</strong> at: <a href='https://wandb.ai/viinod9-iitm/fashion-mnist-nn/runs/cgsgal8g' target=\"_blank\">https://wandb.ai/viinod9-iitm/fashion-mnist-nn/runs/cgsgal8g</a><br> View project at: <a href='https://wandb.ai/viinod9-iitm/fashion-mnist-nn' target=\"_blank\">https://wandb.ai/viinod9-iitm/fashion-mnist-nn</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250308_210600-cgsgal8g/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9s6ztrz7 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: stochastic\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0005\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_init: random\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Ignoring project 'Vinod_A1' when running a sweep."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250308_210647-9s6ztrz7</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/viinod9-iitm/fashion-mnist-nn/runs/9s6ztrz7' target=\"_blank\">solar-sweep-3</a></strong> to <a href='https://wandb.ai/viinod9-iitm/fashion-mnist-nn' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/viinod9-iitm/fashion-mnist-nn/sweeps/nc8rvczp' target=\"_blank\">https://wandb.ai/viinod9-iitm/fashion-mnist-nn/sweeps/nc8rvczp</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/viinod9-iitm/fashion-mnist-nn' target=\"_blank\">https://wandb.ai/viinod9-iitm/fashion-mnist-nn</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/viinod9-iitm/fashion-mnist-nn/sweeps/nc8rvczp' target=\"_blank\">https://wandb.ai/viinod9-iitm/fashion-mnist-nn/sweeps/nc8rvczp</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/viinod9-iitm/fashion-mnist-nn/runs/9s6ztrz7' target=\"_blank\">https://wandb.ai/viinod9-iitm/fashion-mnist-nn/runs/9s6ztrz7</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Ignoring project 'stochastic' when running a sweep."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Acc=0.1008, Train Loss=0.2303, Val Acc=0.0914, Val Loss=0.2303\n",
            "Epoch 2: Train Acc=0.1008, Train Loss=0.2303, Val Acc=0.0914, Val Loss=0.2303\n",
            "Epoch 3: Train Acc=0.1008, Train Loss=0.2303, Val Acc=0.0914, Val Loss=0.2303\n",
            "Epoch 4: Train Acc=0.1008, Train Loss=0.2303, Val Acc=0.0914, Val Loss=0.2303\n",
            "Epoch 5: Train Acc=0.1008, Train Loss=0.2303, Val Acc=0.0914, Val Loss=0.2303\n",
            "Epoch 6: Train Acc=0.1008, Train Loss=0.2303, Val Acc=0.0914, Val Loss=0.2303\n",
            "Epoch 7: Train Acc=0.1008, Train Loss=0.2303, Val Acc=0.0914, Val Loss=0.2303\n",
            "Epoch 8: Train Acc=0.1008, Train Loss=0.2303, Val Acc=0.0914, Val Loss=0.2303\n",
            "Epoch 9: Train Acc=0.1008, Train Loss=0.2303, Val Acc=0.0914, Val Loss=0.2303\n",
            "Epoch 10: Train Acc=0.1008, Train Loss=0.2303, Val Acc=0.0914, Val Loss=0.2303\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_acc</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▇▅▅▄▃▃▂▁▁</td></tr><tr><td>val_acc</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>▁▂▄▅▅▆▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>train_acc</td><td>0.10078</td></tr><tr><td>train_loss</td><td>0.23026</td></tr><tr><td>val_acc</td><td>0.0914</td></tr><tr><td>val_loss</td><td>0.23027</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">Opt-stochastic_Layers-3_HS-64_LR-0.001_Batch-32_Act-relu</strong> at: <a href='https://wandb.ai/viinod9-iitm/fashion-mnist-nn/runs/9s6ztrz7' target=\"_blank\">https://wandb.ai/viinod9-iitm/fashion-mnist-nn/runs/9s6ztrz7</a><br> View project at: <a href='https://wandb.ai/viinod9-iitm/fashion-mnist-nn' target=\"_blank\">https://wandb.ai/viinod9-iitm/fashion-mnist-nn</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250308_210647-9s6ztrz7/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question - 7"
      ],
      "metadata": {
        "id": "Dwa-3knBxv5k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import wandb\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "def load_and_preprocess_data():\n",
        "    (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "    val_size = 5000\n",
        "    x_val, y_val = x_train[:val_size], y_train[:val_size]\n",
        "    x_train, y_train = x_train[val_size:], y_train[val_size:]\n",
        "    x_train, x_val, x_test = x_train / 255.0, x_val / 255.0, x_test / 255.0\n",
        "    y_train = to_categorical(y_train, 10)\n",
        "    y_val = to_categorical(y_val, 10)\n",
        "    y_test = to_categorical(y_test, 10)\n",
        "    return x_train, y_train, x_val, y_val, x_test, y_test\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, config_name):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=range(10), yticklabels=range(10))\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.title(f'Confusion Matrix - {config_name}')\n",
        "\n",
        "    wandb.log({f\"Confusion Matrix - {config_name}\": wandb.Image(plt)})\n",
        "    plt.close()\n",
        "\n",
        "def evaluate_best_configs(best_configs):\n",
        "    x_train, y_train, x_val, y_val, x_test, y_test = load_and_preprocess_data()\n",
        "    y_test_labels = np.argmax(y_test, axis=1)\n",
        "\n",
        "    for config in best_configs:\n",
        "        wandb.init(project=\"fashion-mnist-nn\", name=f\"Confusion_Matrix_{config['name']}\", reinit=True)\n",
        "\n",
        "        if config['optimizer'] == 'rmsprop':\n",
        "            trained_weights = rmsprop_optimizer(config['learning_rate'], x_train, y_train, x_val, y_val, config['epochs'], config['activation'], config['num_layers'], config['hidden_size'], config['weight_init'], config['batch_size'], 28*28, 10)\n",
        "\n",
        "        y_pred_probs, _ = forward_propagation(x_test, trained_weights, config['num_layers'], config['activation'])\n",
        "        y_pred_labels = np.argmax(y_pred_probs, axis=1)\n",
        "        plot_confusion_matrix(y_test_labels, y_pred_labels, config['name'])\n",
        "        wandb.finish()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    best_configs = [\n",
        "        {\n",
        "            'name': 'Best_Config_1',\n",
        "            'epochs': 10,\n",
        "            'num_layers': 5,\n",
        "            'hidden_size': 128,\n",
        "            'learning_rate': 0.0001,\n",
        "            'batch_size': 64,\n",
        "            'optimizer': 'rmsprop',\n",
        "            'weight_decay': 0.5,\n",
        "            'weight_init': 'xavier',\n",
        "            'activation': 'tanh'\n",
        "        },\n",
        "        {\n",
        "            'name': 'Best_Config_2',\n",
        "            'epochs': 10,\n",
        "            'num_layers': 3,\n",
        "            'hidden_size': 128,\n",
        "            'learning_rate': 0.001,\n",
        "            'batch_size': 64,\n",
        "            'optimizer': 'rmsprop',\n",
        "            'weight_decay': 0,\n",
        "            'weight_init': 'xavier',\n",
        "            'activation': 'tanh'\n",
        "        }\n",
        "    ]\n",
        "    evaluate_best_configs(best_configs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zu9PzjZiMjQj",
        "outputId": "9074709e-0061-4258-ba03-be2e1af0c727"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Ignoring project 'fashion-mnist-nn' when running a sweep."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250308_213305-9s6ztrz7</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/viinod9-iitm/fashion-mnist-nn/runs/9s6ztrz7' target=\"_blank\">Confusion_Matrix_Best_Config_1</a></strong> to <a href='https://wandb.ai/viinod9-iitm/fashion-mnist-nn' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/viinod9-iitm/fashion-mnist-nn/sweeps/nc8rvczp' target=\"_blank\">https://wandb.ai/viinod9-iitm/fashion-mnist-nn/sweeps/nc8rvczp</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/viinod9-iitm/fashion-mnist-nn' target=\"_blank\">https://wandb.ai/viinod9-iitm/fashion-mnist-nn</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/viinod9-iitm/fashion-mnist-nn/sweeps/nc8rvczp' target=\"_blank\">https://wandb.ai/viinod9-iitm/fashion-mnist-nn/sweeps/nc8rvczp</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/viinod9-iitm/fashion-mnist-nn/runs/9s6ztrz7' target=\"_blank\">https://wandb.ai/viinod9-iitm/fashion-mnist-nn/runs/9s6ztrz7</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Ignoring project 'rmsprop' when running a sweep."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Acc=0.8339, Train Loss=0.0463, Val Acc=0.8390, Val Loss=0.0457\n",
            "Epoch 2: Train Acc=0.8517, Train Loss=0.0410, Val Acc=0.8548, Val Loss=0.0411\n",
            "Epoch 3: Train Acc=0.8604, Train Loss=0.0384, Val Acc=0.8614, Val Loss=0.0391\n",
            "Epoch 4: Train Acc=0.8667, Train Loss=0.0366, Val Acc=0.8674, Val Loss=0.0377\n",
            "Epoch 5: Train Acc=0.8721, Train Loss=0.0351, Val Acc=0.8702, Val Loss=0.0367\n",
            "Epoch 6: Train Acc=0.8765, Train Loss=0.0340, Val Acc=0.8706, Val Loss=0.0359\n",
            "Epoch 7: Train Acc=0.8799, Train Loss=0.0330, Val Acc=0.8734, Val Loss=0.0352\n",
            "Epoch 8: Train Acc=0.8826, Train Loss=0.0322, Val Acc=0.8758, Val Loss=0.0346\n",
            "Epoch 9: Train Acc=0.8851, Train Loss=0.0314, Val Acc=0.8774, Val Loss=0.0341\n",
            "Epoch 10: Train Acc=0.8883, Train Loss=0.0307, Val Acc=0.8792, Val Loss=0.0337\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_acc</td><td>▁▃▄▅▆▆▇▇██</td></tr><tr><td>train_loss</td><td>█▆▄▄▃▂▂▂▁▁</td></tr><tr><td>val_acc</td><td>▁▄▅▆▆▇▇▇██</td></tr><tr><td>val_loss</td><td>█▅▄▃▃▂▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>train_acc</td><td>0.88835</td></tr><tr><td>train_loss</td><td>0.03071</td></tr><tr><td>val_acc</td><td>0.8792</td></tr><tr><td>val_loss</td><td>0.03369</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">Confusion_Matrix_Best_Config_1</strong> at: <a href='https://wandb.ai/viinod9-iitm/fashion-mnist-nn/runs/9s6ztrz7' target=\"_blank\">https://wandb.ai/viinod9-iitm/fashion-mnist-nn/runs/9s6ztrz7</a><br> View project at: <a href='https://wandb.ai/viinod9-iitm/fashion-mnist-nn' target=\"_blank\">https://wandb.ai/viinod9-iitm/fashion-mnist-nn</a><br>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250308_213305-9s6ztrz7/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Ignoring project 'fashion-mnist-nn' when running a sweep."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250308_213433-9s6ztrz7</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/viinod9-iitm/fashion-mnist-nn/runs/9s6ztrz7' target=\"_blank\">Confusion_Matrix_Best_Config_2</a></strong> to <a href='https://wandb.ai/viinod9-iitm/fashion-mnist-nn' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/viinod9-iitm/fashion-mnist-nn/sweeps/nc8rvczp' target=\"_blank\">https://wandb.ai/viinod9-iitm/fashion-mnist-nn/sweeps/nc8rvczp</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/viinod9-iitm/fashion-mnist-nn' target=\"_blank\">https://wandb.ai/viinod9-iitm/fashion-mnist-nn</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/viinod9-iitm/fashion-mnist-nn/sweeps/nc8rvczp' target=\"_blank\">https://wandb.ai/viinod9-iitm/fashion-mnist-nn/sweeps/nc8rvczp</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/viinod9-iitm/fashion-mnist-nn/runs/9s6ztrz7' target=\"_blank\">https://wandb.ai/viinod9-iitm/fashion-mnist-nn/runs/9s6ztrz7</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Ignoring project 'rmsprop' when running a sweep."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Acc=0.8435, Train Loss=0.0421, Val Acc=0.8446, Val Loss=0.0427\n",
            "Epoch 2: Train Acc=0.8588, Train Loss=0.0379, Val Acc=0.8528, Val Loss=0.0400\n",
            "Epoch 3: Train Acc=0.8727, Train Loss=0.0340, Val Acc=0.8634, Val Loss=0.0369\n",
            "Epoch 4: Train Acc=0.8825, Train Loss=0.0313, Val Acc=0.8702, Val Loss=0.0350\n",
            "Epoch 5: Train Acc=0.8921, Train Loss=0.0290, Val Acc=0.8774, Val Loss=0.0337\n",
            "Epoch 6: Train Acc=0.8959, Train Loss=0.0279, Val Acc=0.8794, Val Loss=0.0335\n",
            "Epoch 7: Train Acc=0.8989, Train Loss=0.0271, Val Acc=0.8822, Val Loss=0.0338\n",
            "Epoch 8: Train Acc=0.9031, Train Loss=0.0259, Val Acc=0.8818, Val Loss=0.0335\n",
            "Epoch 9: Train Acc=0.9060, Train Loss=0.0252, Val Acc=0.8820, Val Loss=0.0337\n",
            "Epoch 10: Train Acc=0.9037, Train Loss=0.0256, Val Acc=0.8792, Val Loss=0.0349\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_acc</td><td>▁▃▄▅▆▇▇███</td></tr><tr><td>train_loss</td><td>█▆▅▄▃▂▂▁▁▁</td></tr><tr><td>val_acc</td><td>▁▃▄▆▇▇███▇</td></tr><tr><td>val_loss</td><td>█▆▄▂▁▁▁▁▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>train_acc</td><td>0.90369</td></tr><tr><td>train_loss</td><td>0.02556</td></tr><tr><td>val_acc</td><td>0.8792</td></tr><tr><td>val_loss</td><td>0.03486</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">Confusion_Matrix_Best_Config_2</strong> at: <a href='https://wandb.ai/viinod9-iitm/fashion-mnist-nn/runs/9s6ztrz7' target=\"_blank\">https://wandb.ai/viinod9-iitm/fashion-mnist-nn/runs/9s6ztrz7</a><br> View project at: <a href='https://wandb.ai/viinod9-iitm/fashion-mnist-nn' target=\"_blank\">https://wandb.ai/viinod9-iitm/fashion-mnist-nn</a><br>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250308_213433-9s6ztrz7/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question - 8"
      ],
      "metadata": {
        "id": "jBN71q1Ux4BH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    sweep_config = {\n",
        "        'method': 'bayes',\n",
        "        'metric': {'name': 'accuracy', 'goal': 'maximize'},\n",
        "        'parameters': {\n",
        "            'epochs': {'values': [5, 10]},\n",
        "            'num_layers': {'values': [3, 4, 5]},\n",
        "            'hidden_size': {'values': [32, 64, 128]},\n",
        "            'weight_decay': {'values': [0, 0.0005, 0.5]},\n",
        "            'learning_rate': {'values': [1e-3, 1e-4]},\n",
        "            'optimizer': {'values': ['stochastic', 'momentum', 'nag', 'rmsprop', 'adam', 'nadam']},\n",
        "            'batch_size': {'values': [16, 32, 64]},\n",
        "            'weight_init': {'values': ['random', 'xavier']},\n",
        "            'activation': {'values': ['sigmoid', 'tanh', 'relu']},\n",
        "        }\n",
        "    }\n",
        "    sweep_id = wandb.sweep(sweep_config, project=\"MSE\")\n",
        "    wandb.agent(sweep_id, function=train, count=3)\n",
        "\n",
        "def train():\n",
        "    wandb.init(project=\"MSE\")\n",
        "    # wandb.init()\n",
        "    config = wandb.config\n",
        "    run_name = f\"Opt-{config.optimizer}_Layers-{config.num_layers}_HS-{config.hidden_size}_LR-{config.learning_rate}_Batch-{config.batch_size}_Act-{config.activation}\"\n",
        "    wandb.run.name = run_name\n",
        "\n",
        "    # x_train, y_train, x_val, y_val, _, _ = load_and_preprocess_data()\n",
        "\n",
        "    optimizer = config.optimizer\n",
        "\n",
        "    if optimizer == 'stochastic':\n",
        "        trained_weights = stochastic_gradient_descent(config.learning_rate, x_train, y_train, x_val, y_val, config.epochs, config.activation, config.num_layers, config.hidden_size, config.weight_init, config.batch_size, 28*28, 10, loss_function='mse')\n",
        "        # trained_weights = stochastic_gradient_descent(lr, x_train, y_train, x_val, y_val, epochs, activation, num_hidden_layer, num_nodes_hidden_layers, weight, batch_size, input_size, output_size)\n",
        "    elif optimizer == 'momentum':\n",
        "        trained_weights = momentum_gradient_descent(config.learning_rate, x_train, y_train, x_val, y_val, config.epochs, config.activation, config.num_layers, config.hidden_size, config.weight_init, config.batch_size, 28*28, 10, loss_function='mse')\n",
        "    elif optimizer == 'nag':\n",
        "        trained_weights = nesterov_gradient_descent(config.learning_rate, x_train, y_train, x_val, y_val, config.epochs, config.activation, config.num_layers, config.hidden_size, config.weight_init, config.batch_size, 28*28, 10, loss_function='mse')\n",
        "    elif optimizer == 'rmsprop':\n",
        "        trained_weights = rmsprop_optimizer(config.learning_rate, x_train, y_train, x_val, y_val, config.epochs, config.activation, config.num_layers, config.hidden_size, config.weight_init, config.batch_size, 28*28, 10, loss_function='mse')\n",
        "    elif optimizer == 'adam':\n",
        "        trained_weights = adam_optimizer(config.learning_rate, x_train, y_train, x_val, y_val, config.epochs, config.activation, config.num_layers, config.hidden_size, config.weight_init, config.batch_size, 28*28, 10, loss_function='mse')\n",
        "    elif optimizer == 'nadam':\n",
        "        trained_weights = nadam_optimizer(config.learning_rate, x_train, y_train, x_val, y_val, config.epochs, config.activation, config.num_layers, config.hidden_size, config.weight_init, config.batch_size, 28*28, 10, loss_function='mse')\n",
        "\n",
        "    #wandb.log({\"train_acc\": train_acc, \"train_loss\": train_loss, \"val_acc\": val_acc, \"val_loss\": val_loss})\n",
        "\n",
        "    wandb.finish()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "r0eP43yxrQjq",
        "outputId": "0d199ff3-82af-494c-83bb-41729567bf96"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: 1qlwp8s7\n",
            "Sweep URL: https://wandb.ai/viinod9-iitm/MSE/sweeps/1qlwp8s7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: khva0rtb with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: momentum\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_init: random\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Ignoring project 'MSE' when running a sweep."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250308_214012-khva0rtb</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/viinod9-iitm/MSE/runs/khva0rtb' target=\"_blank\">azure-sweep-1</a></strong> to <a href='https://wandb.ai/viinod9-iitm/MSE' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/viinod9-iitm/MSE/sweeps/1qlwp8s7' target=\"_blank\">https://wandb.ai/viinod9-iitm/MSE/sweeps/1qlwp8s7</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/viinod9-iitm/MSE' target=\"_blank\">https://wandb.ai/viinod9-iitm/MSE</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/viinod9-iitm/MSE/sweeps/1qlwp8s7' target=\"_blank\">https://wandb.ai/viinod9-iitm/MSE/sweeps/1qlwp8s7</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/viinod9-iitm/MSE/runs/khva0rtb' target=\"_blank\">https://wandb.ai/viinod9-iitm/MSE/runs/khva0rtb</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Ignoring project 'momentum' when running a sweep."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Acc=0.1008, Train Loss=0.0900, Val Acc=0.0914, Val Loss=0.0900\n",
            "Epoch 2: Train Acc=0.1008, Train Loss=0.0900, Val Acc=0.0914, Val Loss=0.0900\n",
            "Epoch 3: Train Acc=0.1008, Train Loss=0.0900, Val Acc=0.0914, Val Loss=0.0900\n",
            "Epoch 4: Train Acc=0.1008, Train Loss=0.0900, Val Acc=0.0914, Val Loss=0.0900\n",
            "Epoch 5: Train Acc=0.1008, Train Loss=0.0900, Val Acc=0.0914, Val Loss=0.0900\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>train_acc</td><td>▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▄▂▁▁</td></tr><tr><td>val_acc</td><td>▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>▁▄▆▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>train_acc</td><td>0.10078</td></tr><tr><td>train_loss</td><td>0.09</td></tr><tr><td>val_acc</td><td>0.0914</td></tr><tr><td>val_loss</td><td>0.09</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">Opt-momentum_Layers-4_HS-64_LR-0.0001_Batch-16_Act-relu</strong> at: <a href='https://wandb.ai/viinod9-iitm/MSE/runs/khva0rtb' target=\"_blank\">https://wandb.ai/viinod9-iitm/MSE/runs/khva0rtb</a><br> View project at: <a href='https://wandb.ai/viinod9-iitm/MSE' target=\"_blank\">https://wandb.ai/viinod9-iitm/MSE</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250308_214012-khva0rtb/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8g4z9uuu with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_init: random\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Ignoring project 'MSE' when running a sweep."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250308_214038-8g4z9uuu</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/viinod9-iitm/MSE/runs/8g4z9uuu' target=\"_blank\">helpful-sweep-2</a></strong> to <a href='https://wandb.ai/viinod9-iitm/MSE' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/viinod9-iitm/MSE/sweeps/1qlwp8s7' target=\"_blank\">https://wandb.ai/viinod9-iitm/MSE/sweeps/1qlwp8s7</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/viinod9-iitm/MSE' target=\"_blank\">https://wandb.ai/viinod9-iitm/MSE</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/viinod9-iitm/MSE/sweeps/1qlwp8s7' target=\"_blank\">https://wandb.ai/viinod9-iitm/MSE/sweeps/1qlwp8s7</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/viinod9-iitm/MSE/runs/8g4z9uuu' target=\"_blank\">https://wandb.ai/viinod9-iitm/MSE/runs/8g4z9uuu</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Ignoring project 'rmsprop' when running a sweep."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Acc=0.5426, Train Loss=0.0594, Val Acc=0.5394, Val Loss=0.0595\n",
            "Epoch 2: Train Acc=0.7168, Train Loss=0.0354, Val Acc=0.7230, Val Loss=0.0353\n",
            "Epoch 3: Train Acc=0.7901, Train Loss=0.0297, Val Acc=0.7896, Val Loss=0.0299\n",
            "Epoch 4: Train Acc=0.8040, Train Loss=0.0278, Val Acc=0.8024, Val Loss=0.0281\n",
            "Epoch 5: Train Acc=0.8195, Train Loss=0.0253, Val Acc=0.8166, Val Loss=0.0260\n",
            "Epoch 6: Train Acc=0.8523, Train Loss=0.0222, Val Acc=0.8462, Val Loss=0.0233\n",
            "Epoch 7: Train Acc=0.8596, Train Loss=0.0212, Val Acc=0.8512, Val Loss=0.0221\n",
            "Epoch 8: Train Acc=0.8660, Train Loss=0.0202, Val Acc=0.8590, Val Loss=0.0213\n",
            "Epoch 9: Train Acc=0.8681, Train Loss=0.0199, Val Acc=0.8610, Val Loss=0.0212\n",
            "Epoch 10: Train Acc=0.8707, Train Loss=0.0192, Val Acc=0.8608, Val Loss=0.0207\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_acc</td><td>▁▅▆▇▇█████</td></tr><tr><td>train_loss</td><td>█▄▃▃▂▂▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▅▆▇▇█████</td></tr><tr><td>val_loss</td><td>█▄▃▂▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>train_acc</td><td>0.87065</td></tr><tr><td>train_loss</td><td>0.01915</td></tr><tr><td>val_acc</td><td>0.8608</td></tr><tr><td>val_loss</td><td>0.02071</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">Opt-rmsprop_Layers-5_HS-32_LR-0.001_Batch-32_Act-tanh</strong> at: <a href='https://wandb.ai/viinod9-iitm/MSE/runs/8g4z9uuu' target=\"_blank\">https://wandb.ai/viinod9-iitm/MSE/runs/8g4z9uuu</a><br> View project at: <a href='https://wandb.ai/viinod9-iitm/MSE' target=\"_blank\">https://wandb.ai/viinod9-iitm/MSE</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250308_214038-8g4z9uuu/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: oy3blwug with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_init: xavier\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Ignoring project 'MSE' when running a sweep."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250308_214115-oy3blwug</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/viinod9-iitm/MSE/runs/oy3blwug' target=\"_blank\">dry-sweep-3</a></strong> to <a href='https://wandb.ai/viinod9-iitm/MSE' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/viinod9-iitm/MSE/sweeps/1qlwp8s7' target=\"_blank\">https://wandb.ai/viinod9-iitm/MSE/sweeps/1qlwp8s7</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/viinod9-iitm/MSE' target=\"_blank\">https://wandb.ai/viinod9-iitm/MSE</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/viinod9-iitm/MSE/sweeps/1qlwp8s7' target=\"_blank\">https://wandb.ai/viinod9-iitm/MSE/sweeps/1qlwp8s7</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/viinod9-iitm/MSE/runs/oy3blwug' target=\"_blank\">https://wandb.ai/viinod9-iitm/MSE/runs/oy3blwug</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Ignoring project 'rmsprop' when running a sweep."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Acc=0.8495, Train Loss=0.0211, Val Acc=0.8556, Val Loss=0.0209\n",
            "Epoch 2: Train Acc=0.8615, Train Loss=0.0198, Val Acc=0.8624, Val Loss=0.0197\n",
            "Epoch 3: Train Acc=0.8557, Train Loss=0.0207, Val Acc=0.8566, Val Loss=0.0211\n",
            "Epoch 4: Train Acc=0.8574, Train Loss=0.0201, Val Acc=0.8564, Val Loss=0.0202\n",
            "Epoch 5: Train Acc=0.8493, Train Loss=0.0214, Val Acc=0.8420, Val Loss=0.0219\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>train_acc</td><td>▁█▅▆▁</td></tr><tr><td>train_loss</td><td>▇▁▅▂█</td></tr><tr><td>val_acc</td><td>▆█▆▆▁</td></tr><tr><td>val_loss</td><td>▅▁▆▃█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>train_acc</td><td>0.84925</td></tr><tr><td>train_loss</td><td>0.02136</td></tr><tr><td>val_acc</td><td>0.842</td></tr><tr><td>val_loss</td><td>0.0219</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">Opt-rmsprop_Layers-5_HS-128_LR-0.001_Batch-16_Act-relu</strong> at: <a href='https://wandb.ai/viinod9-iitm/MSE/runs/oy3blwug' target=\"_blank\">https://wandb.ai/viinod9-iitm/MSE/runs/oy3blwug</a><br> View project at: <a href='https://wandb.ai/viinod9-iitm/MSE' target=\"_blank\">https://wandb.ai/viinod9-iitm/MSE</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250308_214115-oy3blwug/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question- 10"
      ],
      "metadata": {
        "id": "4PnlFv-ix_15"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess dataset\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "def load_and_preprocess_data_mnist():\n",
        "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "    # Split into train and validation\n",
        "    val_size = 5000\n",
        "    x_val, y_val = x_train[:val_size], y_train[:val_size]\n",
        "    x_train, y_train = x_train[val_size:], y_train[val_size:]\n",
        "\n",
        "    # Normalize dataset\n",
        "    x_train, x_val, x_test = x_train / 255.0, x_val / 255.0, x_test / 255.0\n",
        "\n",
        "    # One-hot encoding\n",
        "    y_train = to_categorical(y_train, 10)\n",
        "    y_val = to_categorical(y_val, 10)\n",
        "    y_test = to_categorical(y_test, 10)\n",
        "\n",
        "    return x_train, y_train, x_val, y_val, x_test, y_test\n",
        "\n",
        "# Load data\n",
        "x_train_mnist, y_train_mnist, x_val_mnist, y_val_mnist, x_test_mnist, y_test_mnist = load_and_preprocess_data_mnist()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n14zwJVXs45m",
        "outputId": "8f22e68f-ea31-47a9-f51b-2c942712ee0b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Set parameters and train\n",
        "# num_hidden_layer = 4\n",
        "# num_nodes_hidden_layers = [128]\n",
        "# weight = 'xavier'\n",
        "# input_size = 28 * 28  # Flattened image size\n",
        "# output_size = 10  # Number of classes\n",
        "# lr = 0.01\n",
        "# batch_size = 64\n",
        "# epochs = 4\n",
        "# activation = 'sigmoid'\n",
        "\n",
        "# trained_weights_mnist1 = nadam_optimizer(lr, x_train_mnist, y_train_mnist, x_val_mnist, y_val_mnist, epochs, activation, num_hidden_layer, num_nodes_hidden_layers, weight, batch_size, input_size, output_size, beta1=0.9, beta2=0.999, epsilon=1e-8, loss_function='cross_entropy')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "AJMXwHeDu8CL",
        "outputId": "c16be41d-6e90-415e-acdb-08f174c515fe"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Ignoring project 'nadam' when running a sweep."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250308_215234-oy3blwug</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/viinod9-iitm/MSE/runs/oy3blwug' target=\"_blank\">Opt-rmsprop_Layers-5_HS-128_LR-0.001_Batch-16_Act-relu</a></strong> to <a href='https://wandb.ai/viinod9-iitm/MSE' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/viinod9-iitm/MSE/sweeps/1qlwp8s7' target=\"_blank\">https://wandb.ai/viinod9-iitm/MSE/sweeps/1qlwp8s7</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/viinod9-iitm/MSE' target=\"_blank\">https://wandb.ai/viinod9-iitm/MSE</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/viinod9-iitm/MSE/sweeps/1qlwp8s7' target=\"_blank\">https://wandb.ai/viinod9-iitm/MSE/sweeps/1qlwp8s7</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/viinod9-iitm/MSE/runs/oy3blwug' target=\"_blank\">https://wandb.ai/viinod9-iitm/MSE/runs/oy3blwug</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Acc=0.9461, Train Loss=0.0190, Val Acc=0.9490, Val Loss=0.0194\n",
            "Epoch 2: Train Acc=0.9620, Train Loss=0.0126, Val Acc=0.9616, Val Loss=0.0148\n",
            "Epoch 3: Train Acc=0.9715, Train Loss=0.0094, Val Acc=0.9658, Val Loss=0.0131\n",
            "Epoch 4: Train Acc=0.9765, Train Loss=0.0077, Val Acc=0.9670, Val Loss=0.0127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Set parameters and train\n",
        "# num_hidden_layer = 4\n",
        "# num_nodes_hidden_layers = [128]\n",
        "# weight = 'xavier'\n",
        "# input_size = 28 * 28  # Flattened image size\n",
        "# output_size = 10  # Number of classes\n",
        "# lr = 0.01\n",
        "# batch_size = 64\n",
        "# epochs = 4\n",
        "# activation = 'sigmoid'\n",
        "\n",
        "# trained_weights_mnist2 = adam_optimizer(lr, x_train_mnist, y_train_mnist, x_val_mnist, y_val_mnist, epochs, activation, num_hidden_layer, num_nodes_hidden_layers, weight, batch_size, input_size, output_size, beta1=0.9, beta2=0.999, epsilon=1e-8, loss_function='cross_entropy')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "guzEuH30vuVs",
        "outputId": "8925edfa-c82e-4969-cb2e-dd54ca4443b0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Ignoring project 'adam' when running a sweep."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Acc=0.9456, Train Loss=0.0186, Val Acc=0.9460, Val Loss=0.0187\n",
            "Epoch 2: Train Acc=0.9665, Train Loss=0.0116, Val Acc=0.9616, Val Loss=0.0135\n",
            "Epoch 3: Train Acc=0.9730, Train Loss=0.0091, Val Acc=0.9654, Val Loss=0.0127\n",
            "Epoch 4: Train Acc=0.9806, Train Loss=0.0067, Val Acc=0.9688, Val Loss=0.0111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Set parameters and train\n",
        "# num_hidden_layer = 4\n",
        "# num_nodes_hidden_layers = [128]\n",
        "# weight = 'xavier'\n",
        "# input_size = 28 * 28\n",
        "# output_size = 10\n",
        "# lr = 0.01\n",
        "# batch_size = 64\n",
        "# epochs = 4\n",
        "# activation = 'sigmoid'\n",
        "\n",
        "# trained_weights_mnist3 = rmsprop_optimizer(lr, x_train_mnist, y_train_mnist, x_val_mnist, y_val_mnist, epochs, activation, num_hidden_layer, num_nodes_hidden_layers, weight, batch_size, input_size, output_size, beta=0.9, epsilon=1e-8, loss_function='cross_entropy')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "h5tln8TOwDPd",
        "outputId": "a2d25766-7609-4149-d6b4-e74995b4809c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Ignoring project 'rmsprop' when running a sweep."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Acc=0.9471, Train Loss=0.0182, Val Acc=0.9530, Val Loss=0.0168\n",
            "Epoch 2: Train Acc=0.9554, Train Loss=0.0162, Val Acc=0.9566, Val Loss=0.0168\n",
            "Epoch 3: Train Acc=0.9609, Train Loss=0.0147, Val Acc=0.9596, Val Loss=0.0174\n",
            "Epoch 4: Train Acc=0.9723, Train Loss=0.0112, Val Acc=0.9672, Val Loss=0.0157\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "szAmEv-lweRO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}